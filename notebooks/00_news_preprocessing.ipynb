{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "100f18d3",
   "metadata": {},
   "source": [
    "# Preprocesado de Noticias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82156e10",
   "metadata": {},
   "source": [
    "Importar todas las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76c4bebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup, MarkupResemblesLocatorWarning\n",
    "import os\n",
    "import re\n",
    "import html\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2e6aac",
   "metadata": {},
   "source": [
    "Definir directorios de donde queremos cargar nuestras noticias y donde queremos guardarlas una vez preprocesadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5659628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han encontrado 7 archivos parquet para procesar.\n",
      "\n",
      "amazon_news.parquet\n",
      "apple_news.parquet\n",
      "google_news.parquet\n",
      "meta_news.parquet\n",
      "microsoft_news.parquet\n",
      "nvidia_news.parquet\n",
      "tesla_news.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Usa el directorio actual del notebook como raíz del proyecto\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Define las rutas a los directorios de datos (raw y processed)\n",
    "RAW_DIR = os.path.join(ROOT_DIR, 'data', 'news', 'raw')\n",
    "OUTPUT_DIR = os.path.join(ROOT_DIR, 'data', 'news', 'processed')\n",
    "\n",
    "# Crea el directorio de salida si no existe\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Lista todos los archivos .parquet en el directorio RAW_DIR\n",
    "parquet_files = [f for f in os.listdir(RAW_DIR) if f.endswith('.parquet')]\n",
    "\n",
    "# Muestra el número total de archivos encontrados\n",
    "print(f\"Se han encontrado {len(parquet_files)} archivos parquet para procesar.\\n\")\n",
    "\n",
    "# Lista los nombres de los archivos encontrados\n",
    "for file in parquet_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89b0f51",
   "metadata": {},
   "source": [
    "Procesamiento de los archivos parquet: en esta sección se limpia y transforma el contenido de cada noticia, eliminando HTML (utilizando BeautifulSoup), normalizando saltos de línea y espacios, para generar una versión lista para la tarea de summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40bee4cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Procesando: amazon_news.parquet\n",
      "Guardado: /home/adiez/Desktop/News2Stock/data/news/processed/amazon_news.parquet (12868 filas)\n",
      "\n",
      "Procesando: apple_news.parquet\n",
      "Guardado: /home/adiez/Desktop/News2Stock/data/news/processed/apple_news.parquet (24766 filas)\n",
      "\n",
      "Procesando: google_news.parquet\n",
      "Guardado: /home/adiez/Desktop/News2Stock/data/news/processed/google_news.parquet (13773 filas)\n",
      "\n",
      "Procesando: meta_news.parquet\n",
      "Guardado: /home/adiez/Desktop/News2Stock/data/news/processed/meta_news.parquet (15938 filas)\n",
      "\n",
      "Procesando: microsoft_news.parquet\n",
      "Guardado: /home/adiez/Desktop/News2Stock/data/news/processed/microsoft_news.parquet (13206 filas)\n",
      "\n",
      "Procesando: nvidia_news.parquet\n",
      "Guardado: /home/adiez/Desktop/News2Stock/data/news/processed/nvidia_news.parquet (10308 filas)\n",
      "\n",
      "Procesando: tesla_news.parquet\n",
      "Guardado: /home/adiez/Desktop/News2Stock/data/news/processed/tesla_news.parquet (27796 filas)\n",
      "\n",
      "Todos los archivos han sido procesados!\n",
      "Archivos guardados en: /home/adiez/Desktop/News2Stock/data/news/processed\n"
     ]
    }
   ],
   "source": [
    "# Ignorar warnings de BeautifulSoup sobre URLs\n",
    "warnings.filterwarnings(\"ignore\", category=MarkupResemblesLocatorWarning)\n",
    "\n",
    "# Procesar cada archivo\n",
    "for filename in parquet_files:\n",
    "    print(f\"\\nProcesando: {filename}\")\n",
    "    \n",
    "    input_path = os.path.join(RAW_DIR, filename)\n",
    "    df = pd.read_parquet(input_path)\n",
    "    \n",
    "    # Eliminar las filas con valores nulos en la columna body y teaser\n",
    "    df = df.dropna(subset=[\"body\", \"teaser\"], how=\"all\").reset_index(drop=True)\n",
    "    \n",
    "    # Limpiar HTML y extraer texto\n",
    "    df[\"clean_body\"] = df[\"body\"].apply(\n",
    "        lambda x: BeautifulSoup(x, \"html.parser\").get_text(separator=\"\\n\", strip=True)\n",
    "    )\n",
    "    \n",
    "    # Convertir entidades HTML a caracteres normales\n",
    "    df[\"clean_body\"] = df[\"clean_body\"].apply(html.unescape)\n",
    "    \n",
    "    # Reemplazar saltos de línea pegados a palabras por un espacio\n",
    "    df[\"clean_body\"] = df[\"clean_body\"].apply(lambda x: re.sub(r'(?<=\\S)\\n(?=\\S)', ' ', x))\n",
    "    \n",
    "    # Reducir saltos de línea múltiples a uno solo\n",
    "    df[\"clean_body\"] = df[\"clean_body\"].apply(lambda x: re.sub(r'\\n+', '\\n', x))\n",
    "    \n",
    "    # Limpiar espacios sobrantes al inicio/final\n",
    "    df[\"clean_body\"] = df[\"clean_body\"].str.strip()\n",
    "    \n",
    "    # Eliminar la columna original body\n",
    "    df = df.drop(columns=[\"body\"])\n",
    "    \n",
    "    # Guardar con el mismo nombre de archivo\n",
    "    output_path = os.path.join(OUTPUT_DIR, filename)\n",
    "    df.to_parquet(output_path, engine=\"pyarrow\", index=False)\n",
    "    print(f\"Guardado: {output_path} ({len(df)} filas)\")\n",
    "\n",
    "print(\"\\nTodos los archivos han sido procesados!\")\n",
    "print(\"Archivos guardados en:\", OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
