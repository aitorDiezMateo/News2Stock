{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b3802d4",
   "metadata": {},
   "source": [
    "# Análisis de Cobertura de GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724d083d",
   "metadata": {},
   "source": [
    "En este notebook se analiza la cobertura del vocabulario del corpus de noticias respecto al modelo preentrenado GloVe. Se evaluará qué porcentaje de palabras del corpus están presentes en GloVe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6d28fe",
   "metadata": {},
   "source": [
    "Importar todas las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8438604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73821a5d",
   "metadata": {},
   "source": [
    "Descargar recursos necesarios de NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd95bbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b14ca5a",
   "metadata": {},
   "source": [
    "Definir directorios de donde queremos cargar los datos resumidos y la ubicación del modelo GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceff891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usa el directorio actual del notebook como raíz del proyecto\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Define las rutas a los directorios de datos\n",
    "SUMMARIES_DIR = os.path.join(ROOT_DIR, 'data', 'news', 'summarized')\n",
    "GLOVE_PATH = os.path.join(ROOT_DIR, 'models', 'glove.2024.wikigiga.300d.txt')\n",
    "\n",
    "print(f\"Directorio de resúmenes: {SUMMARIES_DIR}\")\n",
    "print(f\"Ruta de GloVe: {GLOVE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a963acf6",
   "metadata": {},
   "source": [
    "Cargar dataset de ejemplo para análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9df6ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset\n",
    "df = pd.read_parquet(os.path.join(SUMMARIES_DIR, 'nvidia_news.parquet'), engine=\"pyarrow\")\n",
    "\n",
    "# Concatenar título y resumen\n",
    "df[\"text\"] = df[\"title\"] + \"\\n\\n\" + df[\"body_summary\"]\n",
    "df = df.drop(columns=[\"clean_body\", \"body_summary\", \"teaser\", \"title\", \"author\"])\n",
    "\n",
    "print(f\"Dataset cargado con {len(df)} registros\")\n",
    "print(f\"Primeras filas:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcd776b",
   "metadata": {},
   "source": [
    "Tokenizar todo el texto del corpus y construir vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adff906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizar todo el texto\n",
    "all_words = []\n",
    "for text in df['text']:\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    all_words.extend(tokens)\n",
    "\n",
    "# Contar frecuencias\n",
    "word_counts = Counter(all_words)\n",
    "unique_words = set(word_counts.keys())\n",
    "\n",
    "print(f\"Total de palabras (tokens): {len(all_words):,}\")\n",
    "print(f\"Palabras únicas: {len(unique_words):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5139f04",
   "metadata": {},
   "source": [
    "Cargar vocabulario de GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60fc973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar vocabulario de GloVe (solo palabras, no vectores)\n",
    "glove_vocab = set()\n",
    "with open(GLOVE_PATH, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        word = line.split(' ')[0]  # Primer elemento es la palabra\n",
    "        glove_vocab.add(word)\n",
    "\n",
    "print(f\"Vocabulario de GloVe cargado: {len(glove_vocab):,} palabras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6308638c",
   "metadata": {},
   "source": [
    "Comparar vocabulario del corpus con GloVe y calcular cobertura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b587b881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar vocabularios\n",
    "words_in_glove = unique_words & glove_vocab\n",
    "words_not_in_glove = unique_words - glove_vocab\n",
    "\n",
    "# Calcular cobertura por tokens (considerando frecuencias)\n",
    "total_words = len(all_words)\n",
    "tokens_not_in_glove = sum(count for word, count in word_counts.items() if word not in glove_vocab)\n",
    "token_coverage = ((total_words - tokens_not_in_glove) / total_words) * 100\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"Total de palabras en corpus: {total_words:,}\")\n",
    "print(f\"Palabras únicas en corpus: {len(unique_words):,}\")\n",
    "print(f\"Palabras únicas en GloVe: {len(words_in_glove):,}\")\n",
    "print(f\"Palabras únicas NO en GloVe: {len(words_not_in_glove):,}\")\n",
    "print(f\"Cobertura de tokens (por frecuencia): {token_coverage:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
