{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "525ed9d2",
   "metadata": {},
   "source": [
    "# Embeddings Contextuales con FinBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ad6232",
   "metadata": {},
   "source": [
    "En este notebook se generan embeddings contextuales para las noticias utilizando el modelo FinBERT, especializado en texto financiero. Se utiliza el token CLS como representación del texto completo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2940d2e5",
   "metadata": {},
   "source": [
    "Importar todas las librerías necesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19eb40ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adiez/anaconda3/envs/nlp_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e39bdd",
   "metadata": {},
   "source": [
    "Definir directorios de donde queremos cargar los datos resumidos y donde queremos guardar los embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "874ac7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han encontrado 7 archivos parquet para procesar.\n",
      "\n",
      "amazon_news.parquet\n",
      "apple_news.parquet\n",
      "google_news.parquet\n",
      "meta_news.parquet\n",
      "microsoft_news.parquet\n",
      "nvidia_news.parquet\n",
      "tesla_news.parquet\n"
     ]
    }
   ],
   "source": [
    "# Usa el directorio actual del notebook como raíz del proyecto\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "\n",
    "# Define las rutas a los directorios de datos\n",
    "SUMMARIES_DIR = os.path.join(ROOT_DIR, 'data', 'news', 'summarized')\n",
    "OUTPUT_DIR = os.path.join(ROOT_DIR, 'data', 'news', 'embeddings')\n",
    "\n",
    "# Crea el directorio de salida si no existe\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Lista todos los archivos .parquet en el directorio SUMMARIES_DIR\n",
    "parquet_files = [f for f in os.listdir(SUMMARIES_DIR) if f.endswith('.parquet')]\n",
    "\n",
    "# Muestra el número total de archivos encontrados\n",
    "print(f\"Se han encontrado {len(parquet_files)} archivos parquet para procesar.\\n\")\n",
    "\n",
    "# Lista los nombres de los archivos encontrados\n",
    "for file in parquet_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4914c95a",
   "metadata": {},
   "source": [
    "Cargar modelo FinBERT y tokenizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5822a561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelo FinBERT...\n",
      "Modelo FinBERT cargado.\n",
      "Modelo FinBERT cargado.\n"
     ]
    }
   ],
   "source": [
    "print(\"Cargando modelo FinBERT...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
    "model = AutoModel.from_pretrained(\"ProsusAI/finbert\")\n",
    "model.eval()\n",
    "print(\"Modelo FinBERT cargado.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3e61f3",
   "metadata": {},
   "source": [
    "Configurar dispositivo para procesamiento (GPU o CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98e4e56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "# Mover modelo a GPU si está disponible\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f134d343",
   "metadata": {},
   "source": [
    "Definir función para generar embeddings contextuales usando el token CLS de FinBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "531a5efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_embedding(text):\n",
    "    \"\"\"\n",
    "    Genera embedding contextual para un texto usando FinBERT.\n",
    "    Retorna el embedding del token [CLS] como representación del texto.\n",
    "    \"\"\"\n",
    "    # Tokenizar y preparar inputs\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Obtener embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Usar embedding del token [CLS] (primer token) como representación del texto\n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze()\n",
    "    \n",
    "    return cls_embedding.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75bfd62c",
   "metadata": {},
   "source": [
    "Procesamiento de archivos: para cada archivo se realiza la carga de datos, concatenación de título y resumen, generación de embeddings contextuales y guardado de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d3d49fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/7] Procesando amazon_news.parquet...\n",
      "  Generando embeddings para 12391 textos...\n",
      "    Progreso: 12391/12391 (100.0%)\n",
      "    Progreso: 12391/12391 (100.0%)\n",
      "  Guardado amazon_embeddings_contextual.parquet con 12391 registros y dimensión de embedding 768\n",
      "\n",
      "[2/7] Procesando apple_news.parquet...\n",
      "  Guardado amazon_embeddings_contextual.parquet con 12391 registros y dimensión de embedding 768\n",
      "\n",
      "[2/7] Procesando apple_news.parquet...\n",
      "  Generando embeddings para 24208 textos...\n",
      "  Generando embeddings para 24208 textos...\n",
      "    Progreso: 24208/24208 (100.0%)\n",
      "    Progreso: 24208/24208 (100.0%)\n",
      "  Guardado apple_embeddings_contextual.parquet con 24208 registros y dimensión de embedding 768\n",
      "\n",
      "[3/7] Procesando google_news.parquet...\n",
      "  Generando embeddings para 13341 textos...\n",
      "  Guardado apple_embeddings_contextual.parquet con 24208 registros y dimensión de embedding 768\n",
      "\n",
      "[3/7] Procesando google_news.parquet...\n",
      "  Generando embeddings para 13341 textos...\n",
      "    Progreso: 13341/13341 (100.0%)\n",
      "    Progreso: 13341/13341 (100.0%)\n",
      "  Guardado google_embeddings_contextual.parquet con 13341 registros y dimensión de embedding 768\n",
      "\n",
      "[4/7] Procesando meta_news.parquet...\n",
      "  Generando embeddings para 15187 textos...\n",
      "  Guardado google_embeddings_contextual.parquet con 13341 registros y dimensión de embedding 768\n",
      "\n",
      "[4/7] Procesando meta_news.parquet...\n",
      "  Generando embeddings para 15187 textos...\n",
      "    Progreso: 15187/15187 (100.0%)\n",
      "    Progreso: 15187/15187 (100.0%)\n",
      "  Guardado meta_embeddings_contextual.parquet con 15187 registros y dimensión de embedding 768\n",
      "\n",
      "[5/7] Procesando microsoft_news.parquet...\n",
      "  Se han eliminado 1 filas con texto vacío\n",
      "  Generando embeddings para 12931 textos...\n",
      "  Guardado meta_embeddings_contextual.parquet con 15187 registros y dimensión de embedding 768\n",
      "\n",
      "[5/7] Procesando microsoft_news.parquet...\n",
      "  Se han eliminado 1 filas con texto vacío\n",
      "  Generando embeddings para 12931 textos...\n",
      "    Progreso: 12931/12931 (100.0%)\n",
      "    Progreso: 12931/12931 (100.0%)\n",
      "  Guardado microsoft_embeddings_contextual.parquet con 12931 registros y dimensión de embedding 768\n",
      "\n",
      "[6/7] Procesando nvidia_news.parquet...\n",
      "  Generando embeddings para 10215 textos...\n",
      "  Guardado microsoft_embeddings_contextual.parquet con 12931 registros y dimensión de embedding 768\n",
      "\n",
      "[6/7] Procesando nvidia_news.parquet...\n",
      "  Generando embeddings para 10215 textos...\n",
      "    Progreso: 10215/10215 (100.0%)\n",
      "    Progreso: 10215/10215 (100.0%)\n",
      "  Guardado nvidia_embeddings_contextual.parquet con 10215 registros y dimensión de embedding 768\n",
      "\n",
      "[7/7] Procesando tesla_news.parquet...\n",
      "  Guardado nvidia_embeddings_contextual.parquet con 10215 registros y dimensión de embedding 768\n",
      "\n",
      "[7/7] Procesando tesla_news.parquet...\n",
      "  Generando embeddings para 27131 textos...\n",
      "  Generando embeddings para 27131 textos...\n",
      "    Progreso: 27131/27131 (100.0%)\n",
      "    Progreso: 27131/27131 (100.0%)\n",
      "  Guardado tesla_embeddings_contextual.parquet con 27131 registros y dimensión de embedding 768\n",
      "\n",
      "Todos los archivos han sido procesados exitosamente!\n",
      "Archivos guardados en: /home/adiez/Desktop/News2Stock/data/news/embeddings\n",
      "  Guardado tesla_embeddings_contextual.parquet con 27131 registros y dimensión de embedding 768\n",
      "\n",
      "Todos los archivos han sido procesados exitosamente!\n",
      "Archivos guardados en: /home/adiez/Desktop/News2Stock/data/news/embeddings\n"
     ]
    }
   ],
   "source": [
    "for file_idx, file_name in enumerate(parquet_files, 1):\n",
    "    print(f\"[{file_idx}/{len(parquet_files)}] Procesando {file_name}...\")\n",
    "    \n",
    "    # Cargar dataset\n",
    "    df = pd.read_parquet(os.path.join(SUMMARIES_DIR, file_name), engine=\"pyarrow\")\n",
    "    \n",
    "    # Concatenar título y resumen\n",
    "    df[\"text\"] = df[\"title\"] + \"\\n\\n\" + df[\"body_summary\"]\n",
    "    df = df.drop(columns=[\"clean_body\", \"body_summary\", \"teaser\", \"title\", \"author\"])\n",
    "    \n",
    "    # Eliminar filas con texto vacío\n",
    "    original_count = len(df)\n",
    "    df = df.dropna(subset=['text'])\n",
    "    final_count = len(df)\n",
    "    \n",
    "    if original_count != final_count:\n",
    "        print(f\"  Se han eliminado {original_count - final_count} filas con texto vacío\")\n",
    "    \n",
    "    print(f\"  Generando embeddings para {final_count} textos...\")\n",
    "    \n",
    "    # Generar embeddings con seguimiento de progreso\n",
    "    embeddings = []\n",
    "    for idx, text in enumerate(df['text'], 1):\n",
    "        if idx % 100 == 0 or idx == final_count:\n",
    "            print(f\"    Progreso: {idx}/{final_count} ({100*idx/final_count:.1f}%)\", end='\\r')\n",
    "        embeddings.append(get_text_embedding(text))\n",
    "    \n",
    "    df['embedding'] = embeddings\n",
    "    print()  # Nueva línea después del progreso\n",
    "    \n",
    "    # Guardar en directorio de salida\n",
    "    output_name = file_name.replace('_news.parquet', '_embeddings_contextual.parquet')\n",
    "    output_path = os.path.join(OUTPUT_DIR, output_name)\n",
    "    df.to_parquet(output_path, engine=\"pyarrow\", index=False)\n",
    "    \n",
    "    embedding_dim = len(df['embedding'].iloc[0])\n",
    "    print(f\"  Guardado {output_name} con {len(df)} registros y dimensión de embedding {embedding_dim}\\n\")\n",
    "\n",
    "print(\"Todos los archivos han sido procesados exitosamente!\")\n",
    "print(\"Archivos guardados en:\", OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
